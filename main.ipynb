{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning with PyTorch: Neural Style Transfer\n",
    "# set Google Colab runtime\n",
    "\n",
    "# !pip install torch torchvision\n",
    "# !git clone https://github.com/parth1620/Project-NST.git\n",
    "\n",
    "# loading VSG-19 pretrained model using model subpackage in PyTorch\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "vgg = models.vgg19(pretrained = True)\n",
    "\n",
    "# prints features and classifiers and their layers\n",
    "# for this project, we don't use the classifiers, as we extract the content and style from the layers in the features\n",
    "print(vgg)\n",
    "\n",
    "vgg = vgg.features\n",
    "# see only the features component\n",
    "print(vgg)\n",
    "\n",
    "# parse the gradient, use the pretrained weight without updating it\n",
    "# freeze the model so no gradient computation occurs in the training loop\n",
    "for parameters in vgg.parameters():\n",
    "  parameters.requires_grad_(False)\n",
    "\n",
    "# check and move variables and model to GPU if available, otherwise to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print to check what device was set to\n",
    "print(device)\n",
    "vgg.to(device)\n",
    "\n",
    "# preprocess image\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# create preprocess function\n",
    "# used to resize the image if it is larger than max_size\n",
    "def preprocess(img_path, max_size = 500):\n",
    "  image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "  if max(image.size) > max_size:\n",
    "    size = max_size\n",
    "  else:\n",
    "    size = max(image.size)\n",
    "\n",
    "  # all pre-trained models expect input images normalized in the same way\n",
    "  # loaded in to a range of [0, 1] and then normalized using mean and std values\n",
    "  # mean and std values copied from the torchvision.models manual documentation\n",
    "  img_transforms = T.Compose([\n",
    "                  T.Resize(size),\n",
    "                  T.ToTensor(),\n",
    "                  T.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                              std = [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "  image = img_transforms(image)\n",
    "\n",
    "  # if image in shape of ex (3, 224, 224) (c, h w) -> (1, 3, 224, 224)\n",
    "  image = image.unsqueeze(0)\n",
    "\n",
    "  return image\n",
    "\n",
    "# pass content and style image to preprocess function\n",
    "content_p = preprocess('/content/Project-NST/content11.jpg')\n",
    "style_p = preprocess('/content/Project-NST/style12.jpg')\n",
    "\n",
    "# pass to GPU\n",
    "content_p = content_p.to(device)\n",
    "style_p = style_p.to(device)\n",
    "\n",
    "# print the shape\n",
    "print(\"Content Shape:\", content_p.shape)\n",
    "print(\"Style Shape:\", style_p.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
