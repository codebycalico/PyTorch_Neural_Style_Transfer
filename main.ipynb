{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning with PyTorch: Neural Style Transfer\n",
    "# set Google Colab runtime\n",
    "\n",
    "# !pip install torch torchvision\n",
    "# !git clone https://github.com/parth1620/Project-NST.git\n",
    "\n",
    "# loading VSG-19 pretrained model using model subpackage in PyTorch\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "vgg = models.vgg19(pretrained = True)\n",
    "\n",
    "# prints features and classifiers and their layers\n",
    "# for this project, we don't use the classifiers, as we extract the content and style from the layers in the features\n",
    "print(vgg)\n",
    "\n",
    "vgg = vgg.features\n",
    "# see only the features component\n",
    "print(vgg)\n",
    "\n",
    "# parse the gradient, use the pretrained weight without updating it\n",
    "# freeze the model so no gradient computation occurs in the training loop\n",
    "for parameters in vgg.parameters():\n",
    "  parameters.requires_grad_(False)\n",
    "\n",
    "# check and move variables and model to GPU if available, otherwise to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print to check what device was set to\n",
    "print(device)\n",
    "vgg.to(device)\n",
    "\n",
    "# preprocess image\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# create preprocess function\n",
    "# used to resize the image if it is larger than max_size\n",
    "def preprocess(img_path, max_size = 500):\n",
    "  image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "  if max(image.size) > max_size:\n",
    "    size = max_size\n",
    "  else:\n",
    "    size = max(image.size)\n",
    "\n",
    "  # all pre-trained models expect input images normalized in the same way\n",
    "  # loaded in to a range of [0, 1] and then normalized using mean and std values\n",
    "  # mean and std values copied from the torchvision.models manual documentation\n",
    "  img_transforms = T.Compose([\n",
    "                  T.Resize(size),\n",
    "                  T.ToTensor(),\n",
    "                  T.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                              std = [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "  image = img_transforms(image)\n",
    "\n",
    "  # if image in shape of (channel, height, width) -> (batch size, channel, height, width)\n",
    "  image = image.unsqueeze(0)\n",
    "\n",
    "  return image\n",
    "\n",
    "# pass content and style image to preprocess function\n",
    "content_p = preprocess('/content/Project-NST/content11.jpg')\n",
    "style_p = preprocess('/content/Project-NST/style12.jpg')\n",
    "\n",
    "# pass to GPU\n",
    "content_p = content_p.to(device)\n",
    "style_p = style_p.to(device)\n",
    "\n",
    "# print the shape\n",
    "print(\"Content Shape:\", content_p.shape)\n",
    "print(\"Style Shape:\", style_p.shape)\n",
    "\n",
    "# deprocess image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# deprocess the image to plot the image\n",
    "# opposide of the preprocess\n",
    "\n",
    "def deprocess(tensor):\n",
    "  # to plot content and style image, we pass content tensor and style tensor to cpu\n",
    "  image = tensor.to('cpu').clone()\n",
    "  image = image.numpy()\n",
    "\n",
    "  # (batch size, channel, height, width) -> (channel, height, width)\n",
    "  image = image.squeeze(0)\n",
    "\n",
    "  # (channel, height, width) -> (height, width, channel)\n",
    "  image = image.transpose(1, 2, 0)\n",
    "\n",
    "  # denormalize image with std value and mean value\n",
    "  image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "\n",
    "  image = image.clip(0,1)\n",
    "\n",
    "  return image\n",
    "\n",
    "# deprocess content and style tensor\n",
    "content_d = deprocess(content_p)\n",
    "style_d = deprocess(style_p)\n",
    "\n",
    "# print shape\n",
    "print(\"Deprocess Content Shape:\", content_d.shape)\n",
    "print(\"Deprocess Style Shape:\", style_d.shape)\n",
    "\n",
    "# plot the images using matplotlib\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "\n",
    "ax1.imshow(content_d)\n",
    "ax2.imshow(style_d)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
